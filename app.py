import streamlit as st
import json
import pickle
import os
from dotenv import load_dotenv
from BM_25 import load_students, load_jsonl_file, preprocess_jobs, build_bm25_model, match_students_to_jobs
from chatbot_together import analyze_matches

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
load_dotenv()
os.environ["LANGCHAIN_TRACING_V2"] = "true"
BASE_DIR = os.path.dirname(__file__)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Streamlit App â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
st.set_page_config(page_title="Profeshare Job Matcher", layout="wide")
st.title("ğŸ” Profeshare Job Matcher")

# --- Inputs ---
uploaded_file = st.file_uploader("ğŸ“ Upload student profile JSON file", type=["json"])
interest_input = st.text_input(
    "ğŸ’¡ Enter interests (separated by '+')", 
    placeholder="e.g. frontend+developer+>10LPA+hybrid"
)

if uploaded_file and interest_input:
    # â”€â”€â”€â”€â”€ Parse & Validate Uploaded JSON â”€â”€â”€â”€â”€ #
    raw = uploaded_file.read()
    if not raw:
        st.error("âŒ Uploaded file was empty.")
        st.stop()

    try:
        student_data = json.loads(raw)
    except json.JSONDecodeError as e:
        st.error(f"âŒ Could not parse uploaded JSON: {e}")
        st.stop()

    if not isinstance(student_data, list):
        student_data = [student_data]

    # â”€â”€â”€â”€â”€ Update Interests in the Payload â”€â”€â”€â”€â”€ #
    interest_list = [tok.strip() for tok in interest_input.split("+") if tok.strip()]
    for student in student_data:
        student.setdefault("job_preferences", {})["interests"] = interest_list

    # â”€â”€â”€â”€â”€ Save Temp Student File â”€â”€â”€â”€â”€ #
    students_path = os.path.join(BASE_DIR, "students.json")
    with open(students_path, "w") as f:
        json.dump(student_data, f, indent=2)
    st.success("âœ… Interests updated and student profile processed!")

    # â”€â”€â”€â”€â”€ Load & Preprocess Job Data â”€â”€â”€â”€â”€ #
    part_files = ["part_1.jsonl", "part_2.jsonl", "part_3.jsonl"]
    jobs = []
    for fname in part_files:
        path = os.path.join(BASE_DIR, fname)
        if not os.path.exists(path):
            st.error(f"âŒ Missing file in repo: {fname}")
            st.stop()

        try:
            raw_lines = open(path, "r").read().splitlines()
            # skip blank lines
            records = [json.loads(line) for line in raw_lines if line.strip()]
        except Exception as e:
            st.error(f"âŒ Error loading {fname}: {e}")
            st.stop()

        jobs.extend(records)

    job_texts, job_index = preprocess_jobs(jobs)
    bm25 = build_bm25_model(job_texts)
    st.success(f"âœ… Loaded and indexed {len(jobs)} jobs")

    # â”€â”€â”€â”€â”€ Match Students to Jobs â”€â”€â”€â”€â”€ #
    matches = match_students_to_jobs(
        student_data, jobs, bm25, job_index, top_n=10
    )
    pickle_path = os.path.join(BASE_DIR, "student_job_matches.pkl")
    with open(pickle_path, "wb") as f:
        pickle.dump(matches, f)
    st.success("ğŸ¯ Top job matches generated using BM25!")
    st.write(matches)

    # â”€â”€â”€â”€â”€ LLM Reasoning on Matches â”€â”€â”€â”€â”€ #
    try:
        final_resp = analyze_matches(pickle_path, student_data)
        st.markdown("## ğŸ¤– LLM Career Analysis")
        st.write(final_resp)
    except Exception as e:
        st.error(f"âŒ LLM reasoning failed: {e}")
